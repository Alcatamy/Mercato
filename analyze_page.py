#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AnÃ¡lisis del HTML de FutbolFantasy para entender la estructura
"""

import requests
from bs4 import BeautifulSoup
import re

def analyze_page():
    url = "https://www.futbolfantasy.com/analytics/laliga-fantasy/mercado"
    print(f"ğŸ” Analizando estructura de: {url}")
    
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    response = requests.get(url, headers=headers, timeout=15)
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Buscar elementos que contengan informaciÃ³n de jugadores
    print("\nğŸ“‹ Buscando elementos con datos de jugadores...")
    
    # MÃ©todo 1: Buscar por texto que contenga posiciones
    page_text = soup.get_text()
    lines = page_text.split('\n')
    
    player_lines = []
    for line in lines:
        if any(pos in line for pos in ['DEL', 'MED', 'DEF', 'POR']) and ('Real Madrid' in line or 'Barcelona' in line or 'Valencia' in line):
            player_lines.append(line.strip())
    
    print(f"ğŸ“ LÃ­neas encontradas con informaciÃ³n de jugadores: {len(player_lines)}")
    
    for i, line in enumerate(player_lines[:10]):  # Solo mostrar las primeras 10
        print(f"  {i+1:2d}. {line}")
    
    # MÃ©todo 2: Buscar en el HTML elementos especÃ­ficos
    print(f"\nğŸ” Buscando elementos HTML...")
    
    # Buscar divs, spans o elementos que contengan nombres de equipos conocidos
    teams = ['Real Madrid', 'Barcelona', 'Valencia', 'AtlÃ©tico', 'Sevilla']
    for team in teams:
        elements = soup.find_all(text=re.compile(team, re.IGNORECASE))
        if elements:
            print(f"  ğŸŸï¸  {team}: {len(elements)} menciones encontradas")
            
            # Buscar el contexto de estos elementos
            for element in elements[:3]:  # Solo los primeros 3
                parent = element.parent
                if parent:
                    print(f"    ğŸ“„ Contexto: {parent.get_text()[:100]}...")
    
    # MÃ©todo 3: Buscar patrones de precio
    print(f"\nğŸ’° Buscando patrones de precios...")
    price_patterns = [
        r'\d+\.\d+\.\d+',  # Formato 15.340.000
        r'\d+\.\d+',       # Formato 15.340
        r'\d{6,}',         # NÃºmeros grandes (6+ dÃ­gitos)
    ]
    
    for pattern in price_patterns:
        matches = re.findall(pattern, page_text)
        if matches:
            print(f"  ğŸ’µ PatrÃ³n {pattern}: {len(matches)} coincidencias")
            print(f"    ğŸ“Š Ejemplos: {matches[:5]}")
    
    # MÃ©todo 4: Buscar elementos con clases especÃ­ficas
    print(f"\nğŸ¨ Buscando elementos con clases relevantes...")
    
    potential_classes = ['player', 'market', 'table', 'row', 'data']
    for class_name in potential_classes:
        elements = soup.find_all(attrs={'class': re.compile(class_name, re.IGNORECASE)})
        if elements:
            print(f"  ğŸ·ï¸  Clase *{class_name}*: {len(elements)} elementos")
    
    # MÃ©todo 5: Mostrar una muestra del HTML
    print(f"\nğŸ“œ Muestra del HTML (primeros 2000 caracteres):")
    print("=" * 60)
    print(response.text[:2000])
    print("=" * 60)

if __name__ == "__main__":
    analyze_page()
